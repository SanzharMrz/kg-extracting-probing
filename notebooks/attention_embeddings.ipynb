{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9ggK4kSb5eU",
    "outputId": "277ec815-a768-4739-feb8-b5e79e866295"
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "#!pip install --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "45XGTF9sxoi_"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import string\n",
    "import en_core_web_sm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel, GPT2Model, AutoModelForTokenClassification, pipeline\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7nlxSDhiuY7",
    "outputId": "2da48fcb-dbcc-4a88-e73f-7b291bb99e67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Анастасия\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Анастасия\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation += '’'\n",
    "string.punctuation += '–'\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ky1gZnF0zTyN"
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ErL0Tce6B3CG"
   },
   "outputs": [],
   "source": [
    "def get_embs_for_triplets(triplets, sentence_mapping, attention, attentions_types, with_label=False):\n",
    "    sent_embeddings = []\n",
    "      \n",
    "    for triplet in triplets:\n",
    "        #  tokenize target the same way as sentence to avoid index error\n",
    "        if ',' in triplet[0] or \"'\" in triplet[0]:\n",
    "            head = ' '.join(word_tokenize(triplet[0]))\n",
    "        else:\n",
    "            head = triplet[0]\n",
    "      \n",
    "        if ',' in triplet[1] or \"'\" in triplet[1]:\n",
    "            tail = ' '.join(word_tokenize(triplet[1]))\n",
    "        else:\n",
    "            tail = triplet[1]\n",
    "      \n",
    "        if ',' in triplet[2] or \"'\" in triplet[2]:\n",
    "            rel = ' '.join(word_tokenize(triplet[2]))\n",
    "        else:\n",
    "            rel = triplet[2]\n",
    "        \n",
    "        try:\n",
    "            if head in sentence_mapping and tail in sentence_mapping and rel in sentence_mapping:\n",
    "                #  get head, tail, rel indices in the matrix (len(sentence_mapping) == len(att_matrix)) \n",
    "                head_ind = sentence_mapping.index(head)\n",
    "                tail_ind = sentence_mapping.index(tail)\n",
    "                rel_ind = sentence_mapping.index(rel)   \n",
    "                \n",
    "                #  get vector of attention from every head\n",
    "                head_rel_emb = attention[:, head_ind, rel_ind]\n",
    "                rel_tail_emb = attention[:, rel_ind, tail_ind]\n",
    "                head_tail_emb = attention[:, head_ind, tail_ind]\n",
    "                rel_head_emb = attention[:, rel_ind, head_ind]\n",
    "                tail_rel_emb = attention[:, tail_ind, rel_ind]\n",
    "                tail_head_emb = attention[:, tail_ind, head_ind]\n",
    "                #  add LMMS vectorization here?\n",
    "                \n",
    "                #  choose only neede vectors\n",
    "                [1 1 1 0 0 0 1 1]\n",
    "                attentions_to_be_used = [head_rel_emb, rel_tail_emb, head_tail_emb, rel_head_emb, tail_rel_emb, tail_head_emb] \n",
    "                attentions_to_use = tuple([att for i, att in enumerate(attentions_to_be_used) if attentions_types[i] == 1])\n",
    "\n",
    "                #  concat chosen vectors into one\n",
    "                triplet_emb = np.concatenate(attentions_to_use, axis=0).squeeze()\n",
    "\n",
    "                #  add label if 'train' \n",
    "                if with_label:\n",
    "                    rel_label = triplet[3]\n",
    "                    sent_embeddings.append((triplet_emb, triplet, rel_label))\n",
    "                else:\n",
    "                    sent_embeddings.append((triplet_emb, triplet))\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return sent_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ga3-5NbF_oy6"
   },
   "outputs": [],
   "source": [
    "def return_embeddings(sentence, attentions_types, tokenizer, encoder, nlp, target=None, use_cuda=True, mode='train'):\n",
    "   \n",
    "    tokenizer_name = str(tokenizer.__str__)\n",
    "    rel_pos = ['NN', 'NNP', 'NNS', 'JJR', 'JJS', 'MD', 'POS', 'VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']\n",
    "    head_tail_pos = ['NN', 'NNP', 'NNS', 'PRP']\n",
    "\n",
    "    if mode == 'train':\n",
    "        #  to process data with rel labels from dataset (pass target)\n",
    "        inputs, tokenid2word_mapping, token2id, sentence_mapping = create_mapping_target(sentence, \n",
    "                                                                                         target, \n",
    "                                                                                         return_pt=True, \n",
    "                                                                                         tokenizer=tokenizer)\n",
    "    \n",
    "    else:\n",
    "        #  to process data to predict\n",
    "        outputs, tokenid2word_mapping, token2id, sentence_mapping, noun_chunks = create_mapping(sentence, \n",
    "                                                                                                return_pt=True, \n",
    "                                                                                                nlp=nlp,\n",
    "                                                                                                tokenizer=tokenizer)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            for key in inputs.keys():\n",
    "                inputs[key] = inputs[key].cuda()\n",
    "        try:\n",
    "            outputs = encoder(**inputs, output_attentions=True)\n",
    "        except RuntimeError:\n",
    "            print(sentence_mapping)\n",
    "            return []\n",
    "\n",
    "    attn = outputs[2]   \n",
    "\n",
    "    new_matr = []\n",
    "    \n",
    "    for layer in attn:\n",
    "        for head in layer.squeeze():\n",
    "            if use_cuda:\n",
    "                attn = head.cpu()\n",
    "            attention_matrix = attn.detach().numpy()\n",
    "            attention_matrix = attention_matrix[1:-1, 1:-1]\n",
    "            merged_attention = compress_attention(attention_matrix, tokenid2word_mapping)\n",
    "            new_matr.append(merged_attention)\n",
    "\n",
    "    new_matr = np.array(new_matr)\n",
    "    \n",
    "    #  get candidates for head, tail and rel\n",
    "    words = [token for token in sentence_mapping if token not in string.punctuation]\n",
    "    nn_words = [word for word in words if nltk.pos_tag([word])[0][1] in head_tail_pos]\n",
    "    other_words = [word for word in words if nltk.pos_tag([word])[0][1] in rel_pos]\n",
    "    \n",
    "    sent_embeddings = []\n",
    "\n",
    "    if mode == 'train':\n",
    "        #  get candidate triplets (in this case - for 'garbage class')\n",
    "        triplets = [triplet for triplet in list(product(nn_words, nn_words, other_words)) \n",
    "                        if triplet[0] != triplet[1] and triplet[0] != triplet[2] and triplet[1] != triplet[2] and triplet not in target]\n",
    "        other_triplets = [(t[0], t[1], t[2], '0') for t in triplets]\n",
    "        \n",
    "        #  get embeddings for 'garbage' class\n",
    "        try:\n",
    "            sent_embeddings.extend(get_embs_for_triplets(random.choices(other_triplets, k=len(target)), sentence_mapping, new_matr, attentions_types, with_label=True))\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        #  get embeddings for target class\n",
    "        sent_embeddings.extend(get_embs_for_triplets(target, sentence_mapping, new_matr, attentions_types, with_label=True))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        #  get candidate triplets from the sentence\n",
    "        triplets = [triplet for triplet in list(product(nn_words, nn_words, other_words)) \n",
    "                      if triplet[0] != triplet[1] and triplet[0] != triplet[2] and triplet[1] != triplet[2]]\n",
    "        \n",
    "        #  get embeddings for candidate triplets (to be classified further)\n",
    "        sent_embeddings.extend(get_embs_for_triplets(triplets, sentence_mapping, new_matr, attentions_types, with_label=False))\n",
    "    \n",
    "    return sent_embeddings\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LlCP2XCOeX9J"
   },
   "outputs": [],
   "source": [
    "def get_embeddings_corpus(sample_size, attentions_types):  \n",
    "    nlp = en_core_web_sm.load()\n",
    "    selected_model = 'bert-base-cased'\n",
    "\n",
    "    use_cuda = True\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "\n",
    "    encoder = GPT2Model.from_pretrained(selected_model) if 'gpt' in selected_model.lower() else BertModel.from_pretrained(selected_model)\n",
    "    encoder = encoder.cuda() if use_cuda else encoder.cpu()\n",
    "    encoder.eval()\n",
    "\n",
    "    data = pd.read_csv('trex_data.csv')\n",
    "    data = data.sample(sample_size, random_state=666)\n",
    "\n",
    "    embeddings_train = []\n",
    "        \n",
    "    for ind, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        text = row['text']\n",
    "        target = eval(row['target'])\n",
    "        embeddings = return_embeddings(text, attentions_types, tokenizer, encoder, nlp, target, use_cuda, mode='train')\n",
    "        embeddings_train.extend(embeddings)\n",
    "\n",
    "        with open(f'trex_embeddings_{sample_size}.csv', 'a', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "            for emb in embeddings:\n",
    "                csvwriter.writerow(list(emb))\n",
    "        \n",
    "    return embeddings_train\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "b027375fd8444100acd07b5b0941ca80",
      "a8d3da9bbcc84ed99b29734efb920e46",
      "a42fedea067d4fcf9e1a5adb2d6b67e0",
      "e9066b4128cc42cab97bb966dd5d06fc",
      "75ae982e567e41c293522f5e1bcb9d68",
      "e30d4b963d9340a49af3765ae2e1cff0",
      "294c464a9e0248e39eb66505e5ba40ef",
      "ed66e941257a4664b785a891d3e86097",
      "f2945699b5754faeb743f823ea220006",
      "fb38bd02eab148d7ab5647ca3f9eeea7",
      "dd3a2f593cff44a19881cb7f92cdebd4"
     ]
    },
    "id": "TA7-J25IOjYS",
    "outputId": "0e536ca9-aada-4135-bcd0-4d9f664c7804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b027375fd8444100acd07b5b0941ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attentions_types_example = [1, 1, 0, 0, 0, 0]\n",
    "# attentions_to_be_used = [head_rel, rel_tail, head_tail, rel_head, tail_rel, tail_head] \n",
    "test = get_embeddings_corpus(10, attentions_types_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpPBNcRRtZFJ",
    "outputId": "794a398e-2100-406b-9c22-e2321feba0ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0a9JLpCteel"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "get_attention_embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "294c464a9e0248e39eb66505e5ba40ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ae982e567e41c293522f5e1bcb9d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd3a2f593cff44a19881cb7f92cdebd4",
      "placeholder": "​",
      "style": "IPY_MODEL_fb38bd02eab148d7ab5647ca3f9eeea7",
      "value": " 10/10 [00:01&lt;00:00,  6.34it/s]"
     }
    },
    "a42fedea067d4fcf9e1a5adb2d6b67e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_294c464a9e0248e39eb66505e5ba40ef",
      "placeholder": "​",
      "style": "IPY_MODEL_e30d4b963d9340a49af3765ae2e1cff0",
      "value": "100%"
     }
    },
    "a8d3da9bbcc84ed99b29734efb920e46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b027375fd8444100acd07b5b0941ca80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a42fedea067d4fcf9e1a5adb2d6b67e0",
       "IPY_MODEL_e9066b4128cc42cab97bb966dd5d06fc",
       "IPY_MODEL_75ae982e567e41c293522f5e1bcb9d68"
      ],
      "layout": "IPY_MODEL_a8d3da9bbcc84ed99b29734efb920e46"
     }
    },
    "dd3a2f593cff44a19881cb7f92cdebd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e30d4b963d9340a49af3765ae2e1cff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9066b4128cc42cab97bb966dd5d06fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2945699b5754faeb743f823ea220006",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed66e941257a4664b785a891d3e86097",
      "value": 10
     }
    },
    "ed66e941257a4664b785a891d3e86097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2945699b5754faeb743f823ea220006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb38bd02eab148d7ab5647ca3f9eeea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
